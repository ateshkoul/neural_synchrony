{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.11.2\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import pandas as pd\n",
    "print(f\"Running on PyMC3 v{pm.__version__}\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d4e41724a3b0>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data_clust1_AND.condition = data_clust1_AND.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('test_lme_data.csv')\n",
    "data_clust1_AND = pd.read_csv('FaNoOcc_NeNoOcc_insta_abs_detrend_lme_smile_cluster_beta_data_AND_ori.csv')\n",
    "# data_clust1.head()\n",
    "# data = data.iloc[0:7000,]\n",
    "data_clust1_AND.condition = data_clust1_AND.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n",
    "data_clust1_AND.condition = data_clust1_AND.condition.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyads = len(data_clust1_AND.Dyad_no_Eye_tracker_gaze.unique())\n",
    "dyad_idx = np.array(data_clust1_AND.Dyad_no_Eye_tracker_gaze.str.split(\"_\",n=1, expand = True)[1],dtype='int64')-1\n",
    "\n",
    "with pm.Model() as hierarchical_model_clust_1_AND:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_intercept = pm.Normal(\"mu_intercept\", mu=0.0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigma_intercept\", 5.0)\n",
    "    mu_eye_gaze = pm.Normal(\"mu_eye_gaze\", mu=0.0, sigma=100)\n",
    "    sigma_eye_gaze = pm.HalfNormal(\"sigma_eye_gaze\", 5.0)    \n",
    "  \n",
    "    mu_mouth_size = pm.Normal(\"mu_mouth_size\", mu=0.0, sigma=100)\n",
    "    sigma_mouth_size = pm.HalfNormal(\"sigma_mouth_size\", 5.0)  \n",
    "    \n",
    "    mu_mov = pm.Normal(\"mu_mov\", mu=0.0, sigma=100)\n",
    "    sigma_mov = pm.HalfNormal(\"sigma_mov\", 5.0)     \n",
    "    \n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    # Above we just set mu and sd to a fixed value while here we\n",
    "    # plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    intercept = pm.Normal(\"intercept\", mu=mu_intercept, sigma=sigma_intercept, shape=n_dyads)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    eye_gaze = pm.Normal(\"eye_gaze\", mu=mu_eye_gaze, sigma=sigma_eye_gaze, shape=n_dyads)\n",
    "    mouth_size = pm.Normal(\"mouth_size\", mu=mu_mouth_size, sigma=sigma_mouth_size, shape=n_dyads)\n",
    "    mov = pm.Normal(\"mov\", mu=mu_mov, sigma=sigma_mov, shape=n_dyads)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "    #pdb.set_trace()\n",
    "    feature_est = intercept[dyad_idx]  +  eye_gaze[dyad_idx] * data_clust1_AND.Fun_eyeface_joint.values + mouth_size[dyad_idx] * data_clust1_AND.Fun_mouth_size_joint.values +  mov[dyad_idx] * data_clust1_AND.Fun_ALL_joint.values\n",
    "#     feature_est = intercept[dyad_idx] \n",
    "\n",
    "    # Data likelihood\n",
    "    feature_like = pm.Normal(\"feature_like\", mu=feature_est, sigma=eps, observed=data_clust1_AND.chan_freq_data)\n",
    "#     hierarchical_trace_clust_1_null = pm.sample(5000, tune=5000, target_accept=0.99)\n",
    "#     hierarchical_trace_clust_1_AND = pm.sample(1000, tune=1000, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "# hierarchical_trace_clust_1_AND_save = pm.save_trace(hierarchical_trace_clust_1_AND)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model_clust_1_AND:\n",
    "    hierarchical_trace_clust_1_AND = pm.load_trace(\".model_clust_1_binary_insta_abs_detrend_AND_2500_ori.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.rhat(hierarchical_trace_clust_1_AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-d0d069bbd91c>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data_clust1_XOR.condition = data_clust1_XOR.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('test_lme_data.csv')\n",
    "data_clust1_XOR = pd.read_csv('FaNoOcc_NeNoOcc_insta_abs_detrend_lme_smile_cluster_beta_data_XOR_ori.csv')\n",
    "# data_clust1.head()\n",
    "# data = data.iloc[0:7000,]\n",
    "data_clust1_XOR.condition = data_clust1_XOR.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n",
    "data_clust1_XOR.condition = data_clust1_XOR.condition.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyads = len(data_clust1_XOR.Dyad_no_Eye_tracker_gaze.unique())\n",
    "dyad_idx = np.array(data_clust1_XOR.Dyad_no_Eye_tracker_gaze.str.split(\"_\",n=1, expand = True)[1],dtype='int64')-1\n",
    "\n",
    "with pm.Model() as hierarchical_model_clust_1_XOR:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_intercept = pm.Normal(\"mu_intercept\", mu=0.0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigma_intercept\", 5.0)\n",
    "    mu_eye_gaze = pm.Normal(\"mu_eye_gaze\", mu=0.0, sigma=100)\n",
    "    sigma_eye_gaze = pm.HalfNormal(\"sigma_eye_gaze\", 5.0)    \n",
    "  \n",
    "    mu_mouth_size = pm.Normal(\"mu_mouth_size\", mu=0.0, sigma=100)\n",
    "    sigma_mouth_size = pm.HalfNormal(\"sigma_mouth_size\", 5.0)  \n",
    "    \n",
    "    mu_mov = pm.Normal(\"mu_mov\", mu=0.0, sigma=100)\n",
    "    sigma_mov = pm.HalfNormal(\"sigma_mov\", 5.0)     \n",
    "    \n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    # Above we just set mu and sd to a fixed value while here we\n",
    "    # plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    intercept = pm.Normal(\"intercept\", mu=mu_intercept, sigma=sigma_intercept, shape=n_dyads)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    eye_gaze = pm.Normal(\"eye_gaze\", mu=mu_eye_gaze, sigma=sigma_eye_gaze, shape=n_dyads)\n",
    "    mouth_size = pm.Normal(\"mouth_size\", mu=mu_mouth_size, sigma=sigma_mouth_size, shape=n_dyads)\n",
    "    mov = pm.Normal(\"mov\", mu=mu_mov, sigma=sigma_mov, shape=n_dyads)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "    #pdb.set_trace()\n",
    "    feature_est = intercept[dyad_idx]  +  eye_gaze[dyad_idx] * data_clust1_XOR.Fun_eyeface_joint.values + mouth_size[dyad_idx] * data_clust1_XOR.Fun_mouth_size_joint.values +  mov[dyad_idx] * data_clust1_XOR.Fun_ALL_joint.values\n",
    "#     feature_est = intercept[dyad_idx] \n",
    "\n",
    "    # Data likelihood\n",
    "    feature_like = pm.Normal(\"feature_like\", mu=feature_est, sigma=eps, observed=data_clust1_XOR.chan_freq_data)\n",
    "#     hierarchical_trace_clust_1_null = pm.sample(5000, tune=5000, target_accept=0.99)\n",
    "#     hierarchical_trace_clust_1_XOR = pm.sample(1000, tune=1000, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_1_XOR_save = pm.save_trace(hierarchical_trace_clust_1_XOR)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model_clust_1_XOR:\n",
    "    hierarchical_trace_clust_1_XOR = pm.load_trace(\".model_clust_1_binary_insta_abs_detrend_XOR_2500_ori.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909\n",
      "0.7572\n",
      "0.8978\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(hierarchical_trace_clust_1_XOR['mu_eye_gaze']<0)/len(hierarchical_trace_clust_1_XOR['mu_eye_gaze']))\n",
    "print(np.sum(hierarchical_trace_clust_1_XOR['mu_mouth_size']<0)/len(hierarchical_trace_clust_1_XOR['mu_mouth_size']))\n",
    "print(np.sum(hierarchical_trace_clust_1_XOR['mu_mov']<0)/len(hierarchical_trace_clust_1_XOR['mu_mov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\data\\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\data\\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\stats\\stats.py:145: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XOR</th>\n",
       "      <td>0</td>\n",
       "      <td>-234516.631447</td>\n",
       "      <td>23.176926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643015</td>\n",
       "      <td>289.303905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>1</td>\n",
       "      <td>-234519.900519</td>\n",
       "      <td>22.671295</td>\n",
       "      <td>3.269073</td>\n",
       "      <td>0.356985</td>\n",
       "      <td>289.334957</td>\n",
       "      <td>4.782495</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank            loo      p_loo     d_loo    weight          se       dse  \\\n",
       "XOR     0 -234516.631447  23.176926  0.000000  0.643015  289.303905  0.000000   \n",
       "AND     1 -234519.900519  22.671295  3.269073  0.356985  289.334957  4.782495   \n",
       "\n",
       "     warning loo_scale  \n",
       "XOR    False       log  \n",
       "AND    False       log  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_trace_clust_1_AND_az_model = az.from_pymc3(hierarchical_trace_clust_1_AND)\n",
    "hierarchical_trace_clust_1_XOR_az_model = az.from_pymc3(hierarchical_trace_clust_1_XOR)\n",
    "df_comp_loo_1 = az.compare({\"AND\": hierarchical_trace_clust_1_AND_az_model, \"XOR\": hierarchical_trace_clust_1_XOR_az_model})\n",
    "df_comp_loo_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.rhat(hierarchical_trace_clust_1_XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.11.2\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import pandas as pd\n",
    "print(f\"Running on PyMC3 v{pm.__version__}\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-35519a5e7a54>:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data_clust2_AND.condition = data_clust2_AND.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('test_lme_data.csv')\n",
    "\n",
    "data_clust2_AND = pd.read_csv('FaNoOcc_NeNoOcc_insta_abs_detrend_lme_smile_cluster_gamma_data_AND_ori.csv')\n",
    "# data_clust1.head()\n",
    "# data = data.iloc[0:7000,]\n",
    "data_clust2_AND.condition = data_clust2_AND.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n",
    "data_clust2_AND.condition = data_clust2_AND.condition.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyads = len(data_clust2_AND.Dyad_no_Eye_tracker_gaze.unique())\n",
    "dyad_idx = np.array(data_clust2_AND.Dyad_no_Eye_tracker_gaze.str.split(\"_\",n=1, expand = True)[1],dtype='int64')-1\n",
    "\n",
    "with pm.Model() as hierarchical_model_clust_2_AND:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_intercept = pm.Normal(\"mu_intercept\", mu=0.0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigma_intercept\", 5.0)\n",
    "    mu_eye_gaze = pm.Normal(\"mu_eye_gaze\", mu=0.0, sigma=100)\n",
    "    sigma_eye_gaze = pm.HalfNormal(\"sigma_eye_gaze\", 5.0)    \n",
    "  \n",
    "    mu_mouth_size = pm.Normal(\"mu_mouth_size\", mu=0.0, sigma=100)\n",
    "    sigma_mouth_size = pm.HalfNormal(\"sigma_mouth_size\", 5.0)  \n",
    "    \n",
    "    mu_mov = pm.Normal(\"mu_mov\", mu=0.0, sigma=100)\n",
    "    sigma_mov = pm.HalfNormal(\"sigma_mov\", 5.0)     \n",
    "    \n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    # Above we just set mu and sd to a fixed value while here we\n",
    "    # plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    intercept = pm.Normal(\"intercept\", mu=mu_intercept, sigma=sigma_intercept, shape=n_dyads)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    eye_gaze = pm.Normal(\"eye_gaze\", mu=mu_eye_gaze, sigma=sigma_eye_gaze, shape=n_dyads)\n",
    "    mouth_size = pm.Normal(\"mouth_size\", mu=mu_mouth_size, sigma=sigma_mouth_size, shape=n_dyads)\n",
    "    mov = pm.Normal(\"mov\", mu=mu_mov, sigma=sigma_mov, shape=n_dyads)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "    #pdb.set_trace()\n",
    "    feature_est = intercept[dyad_idx]  +  eye_gaze[dyad_idx] * data_clust2_AND.Fun_eyeface_joint.values + mouth_size[dyad_idx] * data_clust2_AND.Fun_mouth_size_joint.values +  mov[dyad_idx] * data_clust2_AND.Fun_ALL_joint.values\n",
    "#     feature_est = intercept[dyad_idx] \n",
    "\n",
    "    # Data likelihood\n",
    "    feature_like = pm.Normal(\"feature_like\", mu=feature_est, sigma=eps, observed=data_clust2_AND.chan_freq_data)\n",
    "#     hierarchical_trace_clust_1_null = pm.sample(5000, tune=5000, target_accept=0.99)\n",
    "#     hierarchical_trace_clust_2_AND = pm.sample(1000, tune=1000, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_2_AND_save = pm.save_trace(hierarchical_trace_clust_2_AND)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model_clust_2_AND:\n",
    "    hierarchical_trace_clust_2_AND = pm.load_trace(\".model_clust_2_binary_insta_abs_detrend_AND_2500_ori.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.rhat(hierarchical_trace_clust_2_AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-df49e33887fa>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data_clust2_XOR.condition = data_clust2_XOR.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('test_lme_data.csv')\n",
    "data_clust2_XOR = pd.read_csv('FaNoOcc_NeNoOcc_insta_abs_detrend_lme_smile_cluster_gamma_data_XOR_ori.csv')\n",
    "# data_clust1.head()\n",
    "# data = data.iloc[0:7000,]\n",
    "data_clust2_XOR.condition = data_clust2_XOR.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n",
    "data_clust2_XOR.condition = data_clust2_XOR.condition.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyads = len(data_clust2_XOR.Dyad_no_Eye_tracker_gaze.unique())\n",
    "dyad_idx = np.array(data_clust2_XOR.Dyad_no_Eye_tracker_gaze.str.split(\"_\",n=1, expand = True)[1],dtype='int64')-1\n",
    "\n",
    "with pm.Model() as hierarchical_model_clust_2_XOR:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_intercept = pm.Normal(\"mu_intercept\", mu=0.0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigma_intercept\", 5.0)\n",
    "    mu_eye_gaze = pm.Normal(\"mu_eye_gaze\", mu=0.0, sigma=100)\n",
    "    sigma_eye_gaze = pm.HalfNormal(\"sigma_eye_gaze\", 5.0)    \n",
    "  \n",
    "    mu_mouth_size = pm.Normal(\"mu_mouth_size\", mu=0.0, sigma=100)\n",
    "    sigma_mouth_size = pm.HalfNormal(\"sigma_mouth_size\", 5.0)  \n",
    "    \n",
    "    mu_mov = pm.Normal(\"mu_mov\", mu=0.0, sigma=100)\n",
    "    sigma_mov = pm.HalfNormal(\"sigma_mov\", 5.0)     \n",
    "    \n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    # Above we just set mu and sd to a fixed value while here we\n",
    "    # plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    intercept = pm.Normal(\"intercept\", mu=mu_intercept, sigma=sigma_intercept, shape=n_dyads)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    eye_gaze = pm.Normal(\"eye_gaze\", mu=mu_eye_gaze, sigma=sigma_eye_gaze, shape=n_dyads)\n",
    "    mouth_size = pm.Normal(\"mouth_size\", mu=mu_mouth_size, sigma=sigma_mouth_size, shape=n_dyads)\n",
    "    mov = pm.Normal(\"mov\", mu=mu_mov, sigma=sigma_mov, shape=n_dyads)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "    #pdb.set_trace()\n",
    "    feature_est = intercept[dyad_idx]  +  eye_gaze[dyad_idx] * data_clust2_XOR.Fun_eyeface_joint.values + mouth_size[dyad_idx] * data_clust2_XOR.Fun_mouth_size_joint.values +  mov[dyad_idx] * data_clust2_XOR.Fun_ALL_joint.values\n",
    "#     feature_est = intercept[dyad_idx] \n",
    "\n",
    "    # Data likelihood\n",
    "    feature_like = pm.Normal(\"feature_like\", mu=feature_est, sigma=eps, observed=data_clust2_XOR.chan_freq_data)\n",
    "#     hierarchical_trace_clust_1_null = pm.sample(5000, tune=5000, target_accept=0.99)\n",
    "#     hierarchical_trace_clust_2_XOR = pm.sample(1000, tune=1000, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_2_XOR_save = pm.save_trace(hierarchical_trace_clust_2_XOR)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model_clust_2_XOR:\n",
    "    hierarchical_trace_clust_2_XOR = pm.load_trace(\".model_clust_2_binary_insta_abs_detrend_XOR_2500_ori.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4022\n",
      "0.0002\n",
      "0.1174\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(hierarchical_trace_clust_2_AND['mu_eye_gaze']<0)/len(hierarchical_trace_clust_2_AND['mu_eye_gaze']))\n",
    "print(np.sum(hierarchical_trace_clust_2_AND['mu_mouth_size']<0)/len(hierarchical_trace_clust_2_AND['mu_mouth_size']))\n",
    "print(np.sum(hierarchical_trace_clust_2_AND['mu_mov']<0)/len(hierarchical_trace_clust_2_AND['mu_mov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\data\\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\stats\\stats.py:145: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>0</td>\n",
       "      <td>-234261.920793</td>\n",
       "      <td>88.102516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751048</td>\n",
       "      <td>335.566511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOR</th>\n",
       "      <td>1</td>\n",
       "      <td>-234823.783975</td>\n",
       "      <td>73.341602</td>\n",
       "      <td>561.863182</td>\n",
       "      <td>0.248952</td>\n",
       "      <td>339.980429</td>\n",
       "      <td>50.229431</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank            loo      p_loo       d_loo    weight          se  \\\n",
       "AND     0 -234261.920793  88.102516    0.000000  0.751048  335.566511   \n",
       "XOR     1 -234823.783975  73.341602  561.863182  0.248952  339.980429   \n",
       "\n",
       "           dse  warning loo_scale  \n",
       "AND   0.000000    False       log  \n",
       "XOR  50.229431    False       log  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_trace_clust_2_AND_az_model = az.from_pymc3(hierarchical_trace_clust_2_AND)\n",
    "hierarchical_trace_clust_2_XOR_az_model = az.from_pymc3(hierarchical_trace_clust_2_XOR)\n",
    "df_comp_loo_2 = az.compare({\"AND\": hierarchical_trace_clust_2_AND_az_model, \"XOR\": hierarchical_trace_clust_2_XOR_az_model})\n",
    "df_comp_loo_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC3 v3.11.2\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import pandas as pd\n",
    "print(f\"Running on PyMC3 v{pm.__version__}\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-c1adeccd9299>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data_clust3_AND.condition = data_clust3_AND.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('test_lme_data.csv')\n",
    "data_clust3_AND = pd.read_csv('FaNoOcc_NeNoOcc_insta_abs_detrend_lme_smile_cluster_alpha_data_AND_ori.csv')\n",
    "# data_clust1.head()\n",
    "# data = data.iloc[0:7000,]\n",
    "data_clust3_AND.condition = data_clust3_AND.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n",
    "data_clust3_AND.condition = data_clust3_AND.condition.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyads = len(data_clust3_AND.Dyad_no_Eye_tracker_gaze.unique())\n",
    "dyad_idx = np.array(data_clust3_AND.Dyad_no_Eye_tracker_gaze.str.split(\"_\",n=1, expand = True)[1],dtype='int64')-1\n",
    "\n",
    "with pm.Model() as hierarchical_model_clust_3_AND:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_intercept = pm.Normal(\"mu_intercept\", mu=0.0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigma_intercept\", 5.0)\n",
    "    mu_eye_gaze = pm.Normal(\"mu_eye_gaze\", mu=0.0, sigma=100)\n",
    "    sigma_eye_gaze = pm.HalfNormal(\"sigma_eye_gaze\", 5.0)    \n",
    "  \n",
    "    mu_mouth_size = pm.Normal(\"mu_mouth_size\", mu=0.0, sigma=100)\n",
    "    sigma_mouth_size = pm.HalfNormal(\"sigma_mouth_size\", 5.0)  \n",
    "    \n",
    "    mu_mov = pm.Normal(\"mu_mov\", mu=0.0, sigma=100)\n",
    "    sigma_mov = pm.HalfNormal(\"sigma_mov\", 5.0)     \n",
    "    \n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    # Above we just set mu and sd to a fixed value while here we\n",
    "    # plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    intercept = pm.Normal(\"intercept\", mu=mu_intercept, sigma=sigma_intercept, shape=n_dyads)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    eye_gaze = pm.Normal(\"eye_gaze\", mu=mu_eye_gaze, sigma=sigma_eye_gaze, shape=n_dyads)\n",
    "    mouth_size = pm.Normal(\"mouth_size\", mu=mu_mouth_size, sigma=sigma_mouth_size, shape=n_dyads)\n",
    "    mov = pm.Normal(\"mov\", mu=mu_mov, sigma=sigma_mov, shape=n_dyads)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "    #pdb.set_trace()\n",
    "    feature_est = intercept[dyad_idx]  +  eye_gaze[dyad_idx] * data_clust3_AND.Fun_eyeface_joint.values + mouth_size[dyad_idx] * data_clust3_AND.Fun_mouth_size_joint.values +  mov[dyad_idx] * data_clust3_AND.Fun_ALL_joint.values\n",
    "#     feature_est = intercept[dyad_idx] \n",
    "\n",
    "    # Data likelihood\n",
    "    feature_like = pm.Normal(\"feature_like\", mu=feature_est, sigma=eps, observed=data_clust3_AND.chan_freq_data)\n",
    "#     hierarchical_trace_clust_1_null = pm.sample(5000, tune=5000, target_accept=0.99)\n",
    "#     hierarchical_trace_clust_3_AND = pm.sample(samples, tune=tune, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model_clust_3_AND:\n",
    "    hierarchical_trace_clust_3_AND = pm.load_trace(\".model_clust_3_binary_insta_abs_detrend_AND_2500_ori.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6e00c6b13c97>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  data_clust3_XOR.condition = data_clust3_XOR.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('test_lme_data.csv')\n",
    "data_clust3_XOR = pd.read_csv('FaNoOcc_NeNoOcc_insta_abs_detrend_lme_smile_cluster_alpha_data_XOR_ori.csv')\n",
    "# data_clust1.head()\n",
    "# data = data.iloc[0:7000,]\n",
    "data_clust3_XOR.condition = data_clust3_XOR.condition_Smile_auto.str.split(\"_\",n=1, expand = True)[1]\n",
    "data_clust3_XOR.condition = data_clust3_XOR.condition.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyads = len(data_clust3_XOR.Dyad_no_Eye_tracker_gaze.unique())\n",
    "dyad_idx = np.array(data_clust3_XOR.Dyad_no_Eye_tracker_gaze.str.split(\"_\",n=1, expand = True)[1],dtype='int64')-1\n",
    "\n",
    "with pm.Model() as hierarchical_model_clust_3_XOR:\n",
    "    # Hyperpriors for group nodes\n",
    "    mu_intercept = pm.Normal(\"mu_intercept\", mu=0.0, sigma=100)\n",
    "    sigma_intercept = pm.HalfNormal(\"sigma_intercept\", 5.0)\n",
    "    mu_eye_gaze = pm.Normal(\"mu_eye_gaze\", mu=0.0, sigma=100)\n",
    "    sigma_eye_gaze = pm.HalfNormal(\"sigma_eye_gaze\", 5.0)    \n",
    "  \n",
    "    mu_mouth_size = pm.Normal(\"mu_mouth_size\", mu=0.0, sigma=100)\n",
    "    sigma_mouth_size = pm.HalfNormal(\"sigma_mouth_size\", 5.0)  \n",
    "    \n",
    "    mu_mov = pm.Normal(\"mu_mov\", mu=0.0, sigma=100)\n",
    "    sigma_mov = pm.HalfNormal(\"sigma_mov\", 5.0)     \n",
    "    \n",
    "    \n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    # Above we just set mu and sd to a fixed value while here we\n",
    "    # plug in a common group distribution for all a and b (which are\n",
    "    # vectors of length n_counties).\n",
    "    intercept = pm.Normal(\"intercept\", mu=mu_intercept, sigma=sigma_intercept, shape=n_dyads)\n",
    "    # Intercept for each county, distributed around group mean mu_a\n",
    "    eye_gaze = pm.Normal(\"eye_gaze\", mu=mu_eye_gaze, sigma=sigma_eye_gaze, shape=n_dyads)\n",
    "    mouth_size = pm.Normal(\"mouth_size\", mu=mu_mouth_size, sigma=sigma_mouth_size, shape=n_dyads)\n",
    "    mov = pm.Normal(\"mov\", mu=mu_mov, sigma=sigma_mov, shape=n_dyads)\n",
    "    # Model error\n",
    "    eps = pm.HalfCauchy(\"eps\", 5.0)\n",
    "    #pdb.set_trace()\n",
    "    feature_est = intercept[dyad_idx]  +  eye_gaze[dyad_idx] * data_clust3_XOR.Fun_eyeface_joint.values + mouth_size[dyad_idx] * data_clust3_XOR.Fun_mouth_size_joint.values +  mov[dyad_idx] * data_clust3_XOR.Fun_ALL_joint.values\n",
    "#     feature_est = intercept[dyad_idx] \n",
    "\n",
    "    # Data likelihood\n",
    "    feature_like = pm.Normal(\"feature_like\", mu=feature_est, sigma=eps, observed=data_clust3_XOR.chan_freq_data)\n",
    "#     hierarchical_trace_clust_1_null = pm.sample(5000, tune=5000, target_accept=0.99)\n",
    "#     hierarchical_trace_clust_3_XOR = pm.sample(samples, tune=tune, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hierarchical_model_clust_3_XOR:\n",
    "    hierarchical_trace_clust_3_XOR = pm.load_trace(\".model_clust_3_binary_insta_abs_detrend_XOR_2500_ori.trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9084\n",
      "0.0031\n",
      "0.9644\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(hierarchical_trace_clust_3_XOR['mu_eye_gaze']<0)/len(hierarchical_trace_clust_3_XOR['mu_eye_gaze']))\n",
    "print(np.sum(hierarchical_trace_clust_3_XOR['mu_mouth_size']<0)/len(hierarchical_trace_clust_3_XOR['mu_mouth_size']))\n",
    "print(np.sum(hierarchical_trace_clust_3_XOR['mu_mov']<0)/len(hierarchical_trace_clust_3_XOR['mu_mov']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\data\\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\stats\\stats.py:145: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n",
      "  warnings.warn(\n",
      "C:\\Users\\SuperLabPC\\anaconda3\\envs\\pymc\\lib\\site-packages\\arviz\\stats\\stats.py:655: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XOR</th>\n",
       "      <td>0</td>\n",
       "      <td>-234507.656330</td>\n",
       "      <td>32.434327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.507566</td>\n",
       "      <td>265.218812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AND</th>\n",
       "      <td>1</td>\n",
       "      <td>-234508.112473</td>\n",
       "      <td>28.790645</td>\n",
       "      <td>0.456144</td>\n",
       "      <td>0.492434</td>\n",
       "      <td>264.936641</td>\n",
       "      <td>8.168776</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank            loo      p_loo     d_loo    weight          se       dse  \\\n",
       "XOR     0 -234507.656330  32.434327  0.000000  0.507566  265.218812  0.000000   \n",
       "AND     1 -234508.112473  28.790645  0.456144  0.492434  264.936641  8.168776   \n",
       "\n",
       "     warning loo_scale  \n",
       "XOR    False       log  \n",
       "AND     True       log  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchical_trace_clust_3_AND_az_model = az.from_pymc3(hierarchical_trace_clust_3_AND)\n",
    "hierarchical_trace_clust_3_XOR_az_model = az.from_pymc3(hierarchical_trace_clust_3_XOR)\n",
    "df_comp_loo_3 = az.compare({\"AND\": hierarchical_trace_clust_3_AND_az_model, \"XOR\": hierarchical_trace_clust_3_XOR_az_model})\n",
    "df_comp_loo_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.rhat(hierarchical_trace_clust_2_XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_1_AND_az_model = az.from_pymc3(hierarchical_trace_clust_1_AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.loo(hierarchical_trace_clust_1_AND_az_model,hierarchical_model_clust_1_AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_1_XOR_az_model = az.from_pymc3(hierarchical_trace_clust_1_XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.loo(hierarchical_trace_clust_1_XOR_az_model,hierarchical_model_clust_1_XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_2_AND_az_model = az.from_pymc3(hierarchical_trace_clust_2_AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.loo(hierarchical_trace_clust_2_AND_az_model,hierarchical_model_clust_2_AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical_trace_clust_2_XOR_az_model = az.from_pymc3(hierarchical_trace_clust_2_XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.loo(hierarchical_trace_clust_2_XOR_az_model,hierarchical_trace_clust_2_XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp_loo = az.compare({\"AND\": hierarchical_trace_clust_1_AND_az_model, \"XOR\": hierarchical_trace_clust_1_XOR_az_model})\n",
    "# df_comp_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comp_loo_2 = az.compare({\"AND\": hierarchical_trace_clust_2_AND_az_model, \"XOR\": hierarchical_trace_clust_2_XOR_az_model})\n",
    "# df_comp_loo_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_compare(df_comp_loo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.plot_compare(df_comp_loo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm.model_graph.model_to_graphviz(hierarchical_model_clust_2_XOR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_work1",
   "language": "python",
   "name": "pymc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
